{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNe9NN5lkYBRYl6Lm/VUOYk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahuavi/Python-Codes/blob/main/Fault_dataset_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIARGqt-PQhM",
        "outputId": "4d627275-dd93-424f-9b71-d831095d5b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=f7900659eedf1d862bd9233a10545ed7174ae7ae9f4cbade4a52808c17f3372a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:1"
      ],
      "metadata": {
        "id": "FbLGnGBxQxJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"FaultDataset\").getOrCreate()\n",
        "\n",
        "# Load the dataset into a Spark DataFrame\n",
        "df = spark.read.csv(\"FaultDataset.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show the first 5 rows of the DataFrame\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a580ra8GPrxD",
        "outputId": "cfa7b3ec-26e0-4c00-8839-ce474171573d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------------+\n",
            "|        1|        2|        3|        4|        5|        6|        7|        8|        9|       10|       11|       12|       13|       14|       15|       16|       17|       18|       19|       20|fault_detected|\n",
            "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------------+\n",
            "|0.3503125|0.3496875|     0.35|0.3459375|   0.3475|0.3459375| 0.341875|0.3434375|    0.355|0.3553125|0.3459375|   0.3525|   0.3575|0.3590625|  0.35875|0.3484375|0.3590625|     0.35|0.3559375|0.3490625|             0|\n",
            "|0.5090625| 0.484375| 0.046875| 0.071875|     0.06|0.0634375|   0.0575|0.0546875|0.0559375| 0.058125|0.0628125| 0.065625|0.0640625|0.0634375|0.0534375| 0.084375|0.0615625|  0.05375| 0.076875| 0.056875|             0|\n",
            "|0.0928125|   0.0975|0.1096875|   0.1025|  0.09625|0.1053125|  0.09875| 0.098125| 0.091875|0.0909375|  0.09875| 0.103125|      0.1|0.1034375|0.1015625|0.0978125|0.0990625|  0.10375| 0.098125|0.1040625|             0|\n",
            "|  0.09375| 0.089375| 0.091875|0.0996875|0.0909375| 0.096875|0.0940625| 0.096875| 0.096875| 0.099375| 0.099375|0.0959375|0.0959375|0.0940625|  0.09125|0.0996875|  0.09375|0.0934375|0.0971875| 0.094375|             0|\n",
            "| 0.036875|0.0440625| 0.038125|0.0428125|0.0353125|0.0340625| 0.033125|0.0403125|0.0346875| 0.036875| 0.035625|  0.03625|0.0409375| 0.039375|    0.035| 0.040625|0.0384375| 0.036875|     0.04|0.0371875|             0|\n",
            "+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+---------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "WEJK6Mi2Psi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows and columns in the DataFrame\n",
        "print(\"Number of rows:\", df.count())\n",
        "print(\"Number of columns:\", len(df.columns))\n",
        "\n",
        "# Print the schema of the DataFrame\n",
        "df.printSchema()\n",
        "\n",
        "# Get summary statistics of the DataFrame\n",
        "df.describe().show()\n",
        "\n",
        "# Group the data by the \"Fault\" column and count the number of rows in each group\n",
        "df.groupBy(\"fault_detected\").count().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfH0ciAePqz7",
        "outputId": "81b7c290-bd37-4041-dc2e-c71593186fdc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 9292\n",
            "Number of columns: 21\n",
            "root\n",
            " |-- 1: double (nullable = true)\n",
            " |-- 2: double (nullable = true)\n",
            " |-- 3: double (nullable = true)\n",
            " |-- 4: double (nullable = true)\n",
            " |-- 5: double (nullable = true)\n",
            " |-- 6: double (nullable = true)\n",
            " |-- 7: double (nullable = true)\n",
            " |-- 8: double (nullable = true)\n",
            " |-- 9: double (nullable = true)\n",
            " |-- 10: double (nullable = true)\n",
            " |-- 11: double (nullable = true)\n",
            " |-- 12: double (nullable = true)\n",
            " |-- 13: double (nullable = true)\n",
            " |-- 14: double (nullable = true)\n",
            " |-- 15: double (nullable = true)\n",
            " |-- 16: double (nullable = true)\n",
            " |-- 17: double (nullable = true)\n",
            " |-- 18: double (nullable = true)\n",
            " |-- 19: double (nullable = true)\n",
            " |-- 20: double (nullable = true)\n",
            " |-- fault_detected: integer (nullable = true)\n",
            "\n",
            "+-------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+\n",
            "|summary|                  1|                  2|                  3|                  4|                 5|                 6|                 7|                  8|                  9|                10|                 11|                 12|                 13|                14|                 15|                16|                 17|                 18|                19|                 20|    fault_detected|\n",
            "+-------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+\n",
            "|  count|               9292|               9292|               9292|               9292|              9292|              9292|              9292|               9292|               9292|              9292|               9292|               9292|               9292|              9292|               9292|              9292|               9292|               9292|              9292|               9292|              9292|\n",
            "|   mean|0.34162330499354226|0.34263116121394677| 0.3421213812957383|0.34213907124407966|0.3428434405940584|0.3428279366659492|0.3427147008179088|0.34306577566724017|0.34317299155187225|0.3439251842983209| 0.3441075320167876|0.34398424047567727| 0.3441183275936292|0.3448787599547991|0.34489994753551373|0.3458342525828662|0.34563488753766686| 0.3457525290572536|0.3465221427034015|  0.346670724817048|               0.5|\n",
            "| stddev|0.28919489486260785| 0.2890875372793958|0.28916422490616933|0.28916356333107296|0.2889646554403878|0.2890889899729543|0.2891948159883224|0.28919185608065456| 0.2893401858067147| 0.289011538534877|0.28920014487495876| 0.2890708129465896|0.28911804701463106|0.2889821392646809| 0.2891314011350137|0.2888285654988746|0.28892040336707314|0.28915028148431343|0.2887705775702368|0.28900135543931055|0.5000269070362092|\n",
            "|    min|           0.024375|           0.024375|           0.024375|           0.024375|          0.024375|          0.024375|          0.024375|           0.024375|           0.024375|          0.024375|           0.024375|           0.024375|              0.025|             0.025|              0.025|          0.024375|           0.024375|           0.024375|          0.024375|              0.025|                 0|\n",
            "|    max|          1.0809375|          1.2134375|          1.0809375|          1.0809375|         1.0809375|         1.0809375|         1.0809375|          1.0809375|          1.0809375|         1.0809375|          1.0809375|          1.2134375|          1.0809375|         1.2134375|          1.0809375|         1.0809375|          1.0809375|          1.0809375|         1.0809375|          1.0809375|                 1|\n",
            "+-------+-------------------+-------------------+-------------------+-------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+-------------------+-------------------+-------------------+------------------+-------------------+------------------+-------------------+-------------------+------------------+-------------------+------------------+\n",
            "\n",
            "+--------------+-----+\n",
            "|fault_detected|count|\n",
            "+--------------+-----+\n",
            "|             1| 4646|\n",
            "|             0| 4646|\n",
            "+--------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK:2"
      ],
      "metadata": {
        "id": "5RI05L2KRAi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "(trainingData, testData) = df.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Prepare the data for training by assembling the feature columns into a vector\n",
        "assembler = VectorAssembler(inputCols=df.columns[:-1], outputCol=\"features\")\n",
        "trainingData = assembler.transform(trainingData).select(\"features\", \"fault_detected\")\n",
        "testData = assembler.transform(testData).select(\"features\", \"fault_detected\")\n"
      ],
      "metadata": {
        "id": "C7cSUHRTQ_dh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Decision Tree classification model\n",
        "dt = DecisionTreeClassifier(labelCol=\"fault_detected\", featuresCol=\"features\")\n",
        "\n",
        "# Evaluate the performance of the model using Area Under ROC as the metric\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"fault_detected\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Use cross-validation to tune the hyperparameters of the model\n",
        "paramGrid = ParamGridBuilder().addGrid(dt.maxDepth, [2, 5, 10]).build()\n",
        "cv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
        "\n",
        "# Fit the model to the training data\n",
        "cvModel = cv.fit(trainingData)\n",
        "\n",
        "# Make predictions on the test data and evaluate the performance of the model\n",
        "predictions = cvModel.transform(testData)\n",
        "auc = evaluator.evaluate(predictions)\n",
        "\n",
        "# Print the area under ROC for the test data\n",
        "print(\"Area Under ROC:\", auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCBfVpfjROjc",
        "outputId": "2e13d792-9ead-4d85-eac5-b1eac02c027d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area Under ROC: 0.8564325761668536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjSQMqfgSbZZ",
        "outputId": "82c0814b-f19c-45b4-e935-85a17ab11a16"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-2.2.2-py3-none-any.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (9.0.0)\n",
            "Collecting querystring-parser<2\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.9/dist-packages (from mlflow) (2.2.3)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.9/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.9/dist-packages (from mlflow) (3.5.3)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.9/dist-packages (from mlflow) (3.4.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (0.4.3)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.9/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (8.1.3)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.9/dist-packages (from mlflow) (1.22.4)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (3.19.6)\n",
            "Collecting gitpython<4,>=2.1.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting databricks-cli<1,>=0.8.7\n",
            "  Downloading databricks-cli-0.17.5.tar.gz (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.4/82.4 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting alembic<2\n",
            "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<24 in /usr/local/lib/python3.9/dist-packages (from mlflow) (23.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (1.4.46)\n",
            "Collecting shap<1,>=0.40\n",
            "  Downloading shap-0.41.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.4/572.4 KB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<7,>=4.0.0\n",
            "  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 KB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz<2023 in /usr/local/lib/python3.9/dist-packages (from mlflow) (2022.7.1)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.9/dist-packages (from mlflow) (1.4.4)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<7,>=3.7.0 in /usr/local/lib/python3.9/dist-packages (from mlflow) (6.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.9/dist-packages (from mlflow) (2.25.1)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.9/dist-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.9/dist-packages (from mlflow) (2.2.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.9/dist-packages (from mlflow) (1.10.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.9/dist-packages (from mlflow) (6.0)\n",
            "Collecting gunicorn<21\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic<2->mlflow) (4.5.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyjwt>=1.7.0\n",
            "  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.9/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.15.0)\n",
            "Collecting requests<3,>=2.17.3\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.9/dist-packages (from docker<7,>=4.0.0->mlflow) (1.26.15)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from Flask<3->mlflow) (2.2.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from Flask<3->mlflow) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.9/dist-packages (from gunicorn<21->mlflow) (63.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (4.39.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.17.3->mlflow) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.17.3->mlflow) (2.10)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<2->mlflow) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn<2->mlflow) (1.1.1)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.9/dist-packages (from shap<1,>=0.40->mlflow) (4.65.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from shap<1,>=0.40->mlflow) (0.56.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->shap<1,>=0.40->mlflow) (0.39.1)\n",
            "Building wheels for collected packages: databricks-cli\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.17.5-py3-none-any.whl size=143015 sha256=d102ee390b4c18303467d5b12a2e5b7209e6b3d0d2be98b377cb5532806a6ae2\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ac/b1/2c75e46c6ffb00ed09b3c94577a1ea387b75289a2ee04f247d\n",
            "Successfully built databricks-cli\n",
            "Installing collected packages: websocket-client, smmap, slicer, querystring-parser, pyjwt, Mako, gunicorn, charset-normalizer, requests, gitdb, alembic, shap, gitpython, docker, databricks-cli, mlflow\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.2 charset-normalizer-3.1.0 databricks-cli-0.17.5 docker-6.0.1 gitdb-4.0.10 gitpython-3.1.31 gunicorn-20.1.0 mlflow-2.2.2 pyjwt-2.6.0 querystring-parser-1.2.4 requests-2.28.2 shap-0.41.0 slicer-0.0.7 smmap-5.0.0 websocket-client-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "# Start an MLflow run\n",
        "with mlflow.start_run():\n",
        "\n",
        "  # Log the run parameters\n",
        "  mlflow.log_param(\"maxDepth\", 5)\n",
        "\n",
        "  # Split the data into training and testing sets\n",
        "  (trainingData, testData) = df.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "  # Prepare the data for training by assembling the feature columns into a vector\n",
        "  assembler = VectorAssembler(inputCols=df.columns[:-1], outputCol=\"features\")\n",
        "  trainingData = assembler.transform(trainingData).select(\"features\", \"fault_detected\")\n",
        "  testData = assembler.transform(testData).select(\"features\", \"fault_detected\")\n",
        "\n",
        "  # Train the Decision Tree classification model\n",
        "  dt = DecisionTreeClassifier(labelCol=\"fault_detected\", featuresCol=\"features\", maxDepth=5)\n",
        "\n",
        "  # Evaluate the performance of the model using Area Under ROC as the metric\n",
        "  evaluator = BinaryClassificationEvaluator(labelCol=\"fault_detected\", metricName=\"areaUnderROC\")\n",
        "\n",
        "  # Use cross-validation to tune the hyperparameters of the model\n",
        "  paramGrid = ParamGridBuilder().addGrid(dt.maxDepth, [2, 5, 10]).build()\n",
        "  cv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
        "\n",
        "  # Fit the model to the training data\n",
        "  cvModel = cv.fit(trainingData)\n",
        "\n",
        "  # Make predictions on the test data and evaluate the performance of the model\n",
        "  predictions = cvModel.transform(testData)\n",
        "  auc = evaluator.evaluate(predictions)\n",
        "\n",
        "  # Log the area under ROC for the test data\n",
        "  mlflow.log_metric(\"auc\", auc)\n",
        "\n",
        "  # Log the model\n",
        "  mlflow.spark.log_model(cvModel.bestModel, \"model\")\n"
      ],
      "metadata": {
        "id": "34qp1DQmSIMb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kNSEPh-NQ_0Y"
      }
    }
  ]
}